{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.04856497309e-14\n"
     ]
    }
   ],
   "source": [
    "n=15\n",
    "d=15\n",
    "M = np.random.rand(n,d)\n",
    "l,v,r = np.linalg.svd(M)\n",
    "v_full = np.append(np.diag(v), np.zeros((n-d,d)), axis=0)\n",
    "RM = np.dot(np.dot(l,v_full), r)\n",
    "print(np.linalg.norm(M - RM, ord='fro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.92706191089\n"
     ]
    }
   ],
   "source": [
    "# rank 3 approx\n",
    "rank = 3\n",
    "v3 = [v[i] if i < rank else 0 for i in range(len(v))]\n",
    "v3_full = np.append(np.diag(v3), np.zeros((n-d,d)), axis=0)\n",
    "RM3 = np.dot(np.dot(l,v3_full), r)\n",
    "print(np.linalg.norm(M - RM3, ord='fro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set half of the values to 0\n",
    "mask = np.random.randint(0,2,size=M.shape).astype(np.bool)\n",
    "z = np.zeros((n,d))\n",
    "RM3_zero = RM3.copy()\n",
    "RM3_zero[mask] = z[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_error(R, P, Q, rank, beta):\n",
    "    e = 0\n",
    "    for i in xrange(len(R)):\n",
    "        for j in xrange(len(R[i])):\n",
    "            if R[i][j] > 0:\n",
    "                e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "                for k in xrange(rank):\n",
    "                    e = e + (beta/2) * ( pow(P[i][k],2) + pow(Q[k][j],2) )\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_sgd(R, P, Q, K, steps=5000, alpha=0.0001, beta=0.02):\n",
    "    Q = Q.T\n",
    "    for step in xrange(steps):\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                    for k in xrange(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR =  np.dot(P,Q)\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_SVRG(R, P, Q, rank, K, T, alpha, beta):\n",
    "    Q = Q.T\n",
    "    P_last = P\n",
    "    Q_last = Q\n",
    "    errors = [calc_error(R, P, Q, rank, beta)]\n",
    "    #print(errors)\n",
    "    e_old = 1000000\n",
    "    for K_i in range(K):\n",
    "        P_tilde = P_last\n",
    "        Q_tilde = Q_last\n",
    "        P_mu_tilde = np.zeros(P.shape)\n",
    "        Q_mu_tilde = np.zeros(Q.shape)\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                    for k in range(rank):\n",
    "                        P_mu_tilde[i][k] = P_mu_tilde[i][k]  + 2 * eij * Q_tilde[k][j] - beta * P_tilde[i][k]\n",
    "                        Q_mu_tilde[k][j] = Q_mu_tilde[k][j] + 2 * eij * P_tilde[i][k] - beta * Q_tilde[k][j]\n",
    "        P_mu_tilde = P_mu_tilde/rank\n",
    "        Q_mu_tilde = Q_mu_tilde/rank\n",
    "        for _ in range(T):\n",
    "            for i in range(len(R)):\n",
    "                for j in range(len(R[i])):\n",
    "                    if R[i][j] > 0:\n",
    "                        eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                        for k in range(rank):\n",
    "                            P[i][k] = P[i][k] + alpha * ((2 * eij * Q[k][j] - beta * P[i][k]) -(2 * eij * Q_tilde[k][j] - beta * P_tilde[i][k]) + P_mu_tilde[i][k])\n",
    "                            Q[k][j] = Q[k][j] + alpha * ((2 * eij * P[i][k] - beta * Q[k][j]) -\n",
    "                             (2* eij * P_tilde[i][k] - beta * Q_tilde[k][j]) + Q_mu_tilde[k][j])\n",
    "        P_last = P\n",
    "        Q_last = Q\n",
    "        e = 0\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "                    for k in xrange(rank):\n",
    "                        e = e + (beta/2) * ( pow(P[i][k],2) + pow(Q[k][j],2) )\n",
    "        #print(errors)\n",
    "        errors.append(e)\n",
    "        #print(errors)\n",
    "        if e < 0.001 or e > e_old:\n",
    "            break\n",
    "        e_old = e\n",
    "    return P, Q.T, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quantize_num(n, s, qtype, vmin, vmax):\n",
    "    n = n / s\n",
    "    if n > vmax:\n",
    "        return qtype(vmax)\n",
    "    elif n < vmin:\n",
    "        return qtype(vmin)\n",
    "    else:\n",
    "        n2 = qtype(n)\n",
    "        if np.random.rand() > n%1 and n2 < vmax:\n",
    "            return n2+1\n",
    "        return n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_SVRG_LP(R, P, Q, rank, K, T, alpha, beta, bits, data_type):\n",
    "    Q = Q.T\n",
    "    P_last = P\n",
    "    Q_last = Q\n",
    "    max_val = 1.0*((2**(bits-1))-1); min_val = -1.0*((2**(bits-1)))\n",
    "    s = 1/(1.0*2**(bits-1))\n",
    "    errors = [calc_error(R,P.astype(float)*s, Q.astype(float)*s, rank, beta)]\n",
    "    e_old = 1000000\n",
    "    for K_i in range(K):\n",
    "        P_tilde = P_last\n",
    "        Q_tilde = Q_last\n",
    "        P_mu_tilde = np.zeros(P.shape)\n",
    "        Q_mu_tilde = np.zeros(Q.shape)\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i,:].astype(float)*s,Q[:,j].astype(float)*s)\n",
    "                    for k in range(rank):\n",
    "                        P_mu_tilde[i][k] = P_mu_tilde[i][k]  + 2 * eij * Q_tilde[k][j].astype(float)*s - beta * P_tilde[i][k].astype(float)*s\n",
    "                        Q_mu_tilde[k][j] = Q_mu_tilde[k][j] + 2 * eij * P_tilde[i][k].astype(float)*s - beta * Q_tilde[k][j].astype(float)*s\n",
    "        P_mu_tilde = P_mu_tilde/rank\n",
    "        Q_mu_tilde = Q_mu_tilde/rank\n",
    "        for _ in range(T):\n",
    "            for i in range(len(R)):\n",
    "                for j in range(len(R[i])):\n",
    "                    if R[i][j] > 0:\n",
    "                        eij = R[i][j] - np.dot(P[i,:].astype(float)*s,Q[:,j].astype(float)*s)\n",
    "                        for k in range(rank):\n",
    "                            pik = float(P[i][k])*s; qkj = float(Q[k][j])*s;\n",
    "                            qtkj = float(Q_tilde[k][j])*s; ptik = float(P_tilde[i][k])*s;\n",
    "                            qkj = float(Q[k][j])*s; qtkj = float(Q_tilde[k][j])*s;\n",
    "                            pik = pik + alpha * ((2 * eij * qkj - beta * pik) - (2 * eij * qtkj - beta * ptik) + P_mu_tilde[i][k])\n",
    "                            qkj = qkj + alpha * ((2 * eij * pik - beta * qkj) - (2* eij * ptik - beta * qtkj) + Q_mu_tilde[k][j])\n",
    "                            P[i][k] = quantize_num(pik, s, data_type, min_val, max_val)\n",
    "                            Q[k][j] = quantize_num(qkj, s, data_type, min_val, max_val)\n",
    "        P_last = P\n",
    "        Q_last = Q\n",
    "        e = 0\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:].astype(float)*s,Q[:,j].astype(float)*s), 2)\n",
    "                    for k in xrange(rank):\n",
    "                        e = e + (beta/2) * ( pow(P[i][k].astype(float)*s,2) + pow(Q[k][j].astype(float)*s,2) )\n",
    "        errors.append(e)\n",
    "        if e < 0.001 or e > e_old:\n",
    "            break\n",
    "        e_old = e\n",
    "    return P.astype(float)*s, Q.T.astype(float)*s, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization_HALP(R, P, Q, rank, K, T, alpha, beta, bits, data_type):\n",
    "    Q = Q.T\n",
    "    max_val = 1.0*((2**(bits-1))-1); min_val = -1.0*((2**(bits-1)))\n",
    "    s = 0\n",
    "    errors = [calc_error(R,P, Q, rank, beta)]\n",
    "    e_old = 1000000\n",
    "    ZP = np.zeros(P.shape,dtype=data_type)\n",
    "    ZQ = np.zeros(Q.shape,dtype=data_type)\n",
    "    s = 0.0\n",
    "    step = 1\n",
    "    for K_i in range(K):\n",
    "        P = P + ZP.astype(float)*s\n",
    "        Q = Q + ZQ.astype(float)*s\n",
    "        P_mu_tilde = np.zeros(P.shape)\n",
    "        Q_mu_tilde = np.zeros(Q.shape)\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot(P[i,:].astype(float)*s,Q[:,j].astype(float)*s)\n",
    "                    for k in range(rank):\n",
    "                        P_mu_tilde[i][k] = P_mu_tilde[i][k]  + 2 * eij * Q[k][j] - beta * P[i][k]\n",
    "                        Q_mu_tilde[k][j] = Q_mu_tilde[k][j] + 2 * eij * P[i][k] - beta * Q[k][j]\n",
    "        P_mu_tilde = P_mu_tilde/rank\n",
    "        Q_mu_tilde = Q_mu_tilde/rank\n",
    "        step+=0\n",
    "        s = (0.05 /(2**(bits-1)))/step\n",
    "        ZP = np.zeros(P.shape,dtype=data_type)\n",
    "        ZQ = np.zeros(Q.shape,dtype=data_type)\n",
    "        for _ in range(T):\n",
    "            for i in range(len(R)):\n",
    "                for j in range(len(R[i])):\n",
    "                    if R[i][j] > 0:\n",
    "                        eij = R[i][j] - np.dot(P[i,:]+ZP[i,:].astype(float)*s,Q[:,j]+ZQ[:,j].astype(float)*s)\n",
    "                        for k in range(rank):\n",
    "                            zpik = float(ZP[i][k])*s; zqkj = float(ZQ[k][j])*s\n",
    "                            zpik = zpik - alpha * ((2 * eij * (Q[k][j]+zqkj) - beta * (P[i][k])+zpik) -(2 * eij * Q[k][j] - beta * P[i][k]) + P_mu_tilde[i][k])\n",
    "                            zqkj = zqkj - alpha * ((2 * eij * (P[i][k]+zpik) - beta * (Q[k][j]+zqkj)) - (2* eij * P[i][k] - beta * Q[k][j]) + Q_mu_tilde[k][j])\n",
    "                            ZP[i][k] = quantize_num(zpik, s, data_type, min_val, max_val)\n",
    "                            ZQ[k][j] = quantize_num(zqkj, s, data_type, min_val, max_val)\n",
    "        e = 0\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:]+ZP[i,:].astype(float)*s,Q[:,j]+ZQ[:,j].astype(float)*s), 2)\n",
    "                    for k in xrange(rank):\n",
    "                        e = e + (beta/2) * ( pow(P[i][k]+float(ZP[i][k])*s,2) + pow(Q[k][j]+float(ZQ[k][j])*s,2) )\n",
    "        errors.append(e)\n",
    "        if e < 0.001 or e > e_old:\n",
    "            break\n",
    "        e_old = e\n",
    "    return P + ZP.astype(float)*s, Q.T + ZQ.T.astype(float)*s, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_SVRG(epochs, sgd_updates, P_init, Q_init, alpha, beta):\n",
    "    rank = 3\n",
    "    nP, nQ, errors = matrix_factorization_SVRG(RM3_zero, P_init, Q_init, rank, epochs, sgd_updates, alpha, beta)\n",
    "    RM3_est = np.dot(nP,nQ.T)\n",
    "    RM3_est_z = RM3_est.copy()\n",
    "    RM3_est_z[mask] = z[mask]\n",
    "    print(np.linalg.norm(RM3_est_z - RM3_zero, ord='fro'))\n",
    "    print(np.linalg.norm(RM3_est - RM3, ord='fro'))\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_SVRG_LP(epochs, sgd_updates, P_init, Q_init, bits, data_type, alpha, beta):\n",
    "    rank = 3\n",
    "    nP, nQ, errors = matrix_factorization_SVRG_LP(RM3_zero, P_init, Q_init, rank, epochs, sgd_updates, alpha, beta, bits, data_type)\n",
    "    RM3_est = np.dot(nP,nQ.T)\n",
    "    RM3_est_z = RM3_est.copy()\n",
    "    RM3_est_z[mask] = z[mask]\n",
    "    print(np.linalg.norm(RM3_est_z - RM3_zero, ord='fro'))\n",
    "    print(np.linalg.norm(RM3_est - RM3, ord='fro'))\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_HALP(epochs, sgd_updates, P_init, Q_init, bits, data_type, alpha, beta):\n",
    "    rank = 3\n",
    "    nP, nQ, errors = matrix_factorization_HALP(RM3_zero, P_init, Q_init, rank, epochs, sgd_updates, alpha, beta, bits, data_type)\n",
    "    RM3_est = np.dot(nP,nQ.T)\n",
    "    RM3_est_z = RM3_est.copy()\n",
    "    RM3_est_z[mask] = z[mask]\n",
    "    print(np.linalg.norm(RM3_est_z - RM3_zero, ord='fro'))\n",
    "    print(np.linalg.norm(RM3_est - RM3, ord='fro'))\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_gen = np.random.randint(2**15, size=(n, rank),dtype=np.int16)\n",
    "Q_gen = np.random.randint(2**15, size=(d, rank),dtype=np.int16)\n",
    "s = 1/(1.0*2**15)\n",
    "P_full_gen = P_gen.astype(float)*s\n",
    "Q_full_gen = Q_gen.astype(float)*s\n",
    "alpha = 0.00001\n",
    "beta = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09879632788\n",
      "3.4247550068\n"
     ]
    }
   ],
   "source": [
    "errors_SVRG = handle_SVRG(5,1000,P_full_gen.copy(), Q_full_gen.copy(),alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0970255392\n",
      "4.37001816485\n"
     ]
    }
   ],
   "source": [
    "errors_LP_SVRG = handle_SVRG_LP(5,1000, P_gen.copy(), Q_gen.copy(), 16, np.int16, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_HALP = handle_HALP(5,1000, P_full_gen.copy(), Q_full_gen.copy(), 16, np.int16, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.draw_line_graph2(errors_SVRG, errors_LP_SVRG, \"error\", \"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.draw_line_graph3(errors_SVRG, errors_LP_SVRG, errors_HALP, \"error\", \"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
